---
layout: page
title: Vision Language Models Know Law of Conservation without Understanding More-or-Less
subtitle:  
---

[//]: # (<h3 style='margin-bottom: 10pt;'>Topics</h3>)

<center>
<div class="assets">
<a href="https://arxiv.org/abs/2410.00332" target="_blank">[paper]</a>
</div>
</center>

<div class='description' style='font-size: 11pt;margin-bottom: 10pt'>
<h3>Abstract</h3>
<ul>
    Conservation is a critical milestone of cognitive development considered to be supported by both the understanding of quantitative concepts and the reversibility of mental operations. To assess whether this critical component of human intelligence has emerged in Vision Language Models, we leverage the ConserveBench from CogDevelop2K, a data-intensive cognitive experiment benchmark for assaying the developmental trajectory of machine intelligence. The battery includes over 350 questions across four dimensions of physical quantities: volume, solid quantity, length, and number. The former two involve only transformational tasks, whereas the latter two also involve non-transformational tasks assessing the understanding of quantitative concepts alone. Surprisingly, we find that while VLMs are generally capable of conserving, they tend to fail at non-transformational tasks which success is typically considered to be entailed by the ability to conserve. This implies that the law of conservation, at least in concrete domains, may exist without corresponding conceptual understanding of quantity.
</ul>

<h3>Reasoning about Inertia and Motion</h3>
<figure>
    <img src="/img/CogDevelop2K/System2ReasoningatScale_MechReason/Case_5.jpg">
</figure>
</div>


</div>
