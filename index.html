---
layout: home
---

<center>
    <h1>Growing AI like a Child, at Scale</h1>
</center>

<hr class="small" style="border-width: 1pt; border-color: lightgray;">

<div class="description" style="font-size: 13pt;">
<p>Humans never "learn" intelligence. Humans <i>develop</i> intelligence. Biological lives on this planet take heavy advantage of intelligent primitives embedded in their genes. Cats never "learn" to backflip. Birds never "learn" to fly. In the same way, humans never "learn" to <i>cognize</i>. Humans are born with a set of <i>core cognition</i>, that sets the foundation for our perception and action in the physical world. </p>
</div>

<div class="description" style="font-size: 13pt;">
<p>Our <i>core cognition</i> unravels through a specific developmental trajectory as we grow into adulthood. Here, we seek to do the same for our machines, leveraging heavy cognitive literature in developmental psychology, and in particular, Piagetian theory of cognitive development, to design our <i>growing up</i> curriculum. In addition, we also want to learn from the current success of machine intelligence, specifically the <i>scaling</i> law.</p>
</div>

<div class="description" style="font-size: 13pt;">
Instead of putting <i>growing up</i> and <i>scaling up</i> into opposite camps, we argue the next step towards human-like artificial general intelligence is to <i>grow AI like a child, at scale</i>, and call for an open-source collaborative community effort to launch the next step.
</div>

<hr class="small" style="border-width: 1pt; border-color: lightgray;">
<div class="subsubheading"><h2>Join Us: <a href="https://join.slack.com/t/growingailikeachild/shared_invite/zt-2rw1oqto3-I7IsBoawbi6btzBkaTFI8g" target="_blank">Slack</a></h2></div>
<hr class="small" style="border-width: 1pt; border-color: lightgray;">

<h3>Updates</h3>
<div class="publication" style="margin: 3px; font-size: 12pt; font-family:'Times New Roman', Times, serif;">
    <p style="margin: 1px; font-size: 13pt">
        <a href="https://arxiv.org/abs/2410.00332" target="_blank">
            Vision Language Models Know Law of Conservation without Understanding More-or-Less
        </a>
    </p>
    <p style="margin: 1px; font-size: 11pt">
        TLDR: We find that Vision Language Models know the law of conservation but fail at quantitative understanding in a way opposite to human intuitive biases.
    </p>
</div>

<div class="publication" style="margin: 3px; font-size: 12pt; font-family:'Times New Roman', Times, serif;">
    <p style="margin: 1px; font-size: 13pt">
        <a href="https://arxiv.org/abs/2410.00324" target="_blank">
            Vision Language Models See What You Want but not What You See
        </a>
    </p>
    <p style="margin: 1px; font-size: 11pt">
        TLDR: VLMs score high on intentionality understanding but low on perspective-taking, challenging traditional cognitive developmental views on the relationship between these two theory-of-mind abilities.
    </p>
</div>

<div class="publication" style="margin: 3px; font-size: 12pt; font-family:'Times New Roman', Times, serif;">
    <p style="margin: 1px; font-size: 13pt">
        <a href="https://arxiv.org/abs/2410.00318" target="_blank">
            Probing Mechanical Reasoning in Large Vision Language Models
        </a>
    </p>
    <p style="margin: 1px; font-size: 11pt">
        TLDR: We investigated understanding of system stability, pulley and gear systems, seesaw-like systems and leverage principle, and fluid systems, and we observed diverse yet consistent behaviors in VLMs.
    </p>
</div>

<h3>In-Progress</h3>
<div class="in-progress" style="margin: 3px; font-size: 12pt; font-family:'Times New Roman', Times, serif;">
    <ul style="margin: 0; padding-left: 20px; font-size: 13pt;">
        <li>
            We reason that in order to scale up to an infinite number of training materials for embodied VLMs, we need to build the embodied core cognition scenarios suite to generate data, which we call the <i>GalacSuite</i>. We identify 2517 core cognition scenarios from our previous work. We are leveraging <a href="https://mujoco.org/" target="_blank">mujuco</a> to build embodied, physics-based embodied core cognition scenarios suite <i>GalacSuite</i>.
        </li>
    </ul>
    <p style="margin: 1px; font-size: 13pt">
        Feel free to connect with us if you are interested in these projects and wanna join, or you have some really amazing ideas to propose and invite us to work on it/collaborate. We are always happy to chat! 
    </p>
</div>


<!--
<center>
    <figure>
        <img src="material_1.jpg" alt="Logo" style="max-width: 100%; height: auto;">
        <figcaption><a href="https://openreview.net/forum?id=fDNBPqgr4K" target="_blank">CogDevelop2K</a></figcaption>
    </figure>
</center>
-->
